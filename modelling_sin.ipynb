{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datasets...\n",
      "Datasets generated.\n",
      "\n",
      "Plot 'datasets.png' saved.\n",
      "\n",
      "Performing Method 1: Exact GP and KRR...\n",
      "Method 1 completed.\n",
      "\n",
      "Plot 'method1_gp_krr.png' saved.\n",
      "\n",
      "Performing Method 2: Random Fourier Features (RFF)...\n",
      "Method 2 completed.\n",
      "\n",
      "Plot 'method2_rff.png' saved.\n",
      "\n",
      "Performing Method 3: Performer's Random Feature Approach...\n",
      "Method 3 completed.\n",
      "\n",
      "Plot 'method3_performer.png' saved.\n",
      "\n",
      "Computing condition numbers for all methods...\n",
      "Condition Numbers:\n",
      "                           Exact GP  Kernel Ridge           RFF     Performer\n",
      "Dataset 1 (Large Gap)  76567.464789  76567.464789  1.604614e+06  2.500501e+06\n",
      "Dataset 2 (Small Gap)  86482.001239  86482.001239  1.834207e+06  3.751251e+06 \n",
      "\n",
      "Comparison of Methods (Mean Squared Error, CPU Times, and Condition Numbers):\n",
      "                       Exact GP  Kernel Ridge       RFF  Performer  \\\n",
      "Dataset 1 (Large Gap)  0.040202      0.066064  0.015719   0.000019   \n",
      "Dataset 2 (Small Gap)  0.000032      0.000202  0.013026   0.000000   \n",
      "\n",
      "                       Exact GP Fit (s)  Exact GP Predict (s)  KRR Fit (s)  \\\n",
      "Dataset 1 (Large Gap)            3.4921                0.2136       0.1315   \n",
      "Dataset 2 (Small Gap)            8.4597                0.3900       0.3080   \n",
      "\n",
      "                       KRR Predict (s)  RFF Feature Gen (s)  \\\n",
      "Dataset 1 (Large Gap)           0.0650               0.0628   \n",
      "Dataset 2 (Small Gap)           0.0972               0.0674   \n",
      "\n",
      "                       RFF Ridge Fit (s)  RFF Predict (s)  \\\n",
      "Dataset 1 (Large Gap)             0.0310           0.0013   \n",
      "Dataset 2 (Small Gap)             0.0417           0.0012   \n",
      "\n",
      "                       Performer Feature Gen (s)  Performer Ridge Fit (s)  \\\n",
      "Dataset 1 (Large Gap)                     0.0534                   0.0345   \n",
      "Dataset 2 (Small Gap)                     0.0615                   0.0389   \n",
      "\n",
      "                       Performer Predict (s)  Exact GP Cond  \\\n",
      "Dataset 1 (Large Gap)                 0.0012   76567.464789   \n",
      "Dataset 2 (Small Gap)                 0.0013   86482.001239   \n",
      "\n",
      "                       Kernel Ridge Cond      RFF Cond  Performer Cond  \n",
      "Dataset 1 (Large Gap)       76567.464789  1.604614e+06    2.500501e+06  \n",
      "Dataset 2 (Small Gap)       86482.001239  1.834207e+06    3.751251e+06  \n",
      "\n",
      "Summary table saved as 'comparison_table.csv'.\n",
      "\n",
      "All plots, tables, and condition number calculations have been sucesfully generated and saved!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.linalg import qr\n",
    "from sklearn.metrics.pairwise import rbf_kernel  \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# For reproducibility. I.e. when I run multiple times to get same regression result\n",
    "np.random.seed(42)\n",
    "def generate_sine_data(n_samples=5000, noise_std=0.1, gap_type='large'):\n",
    "    \"\"\"\n",
    "    Generates noisy sine data with specified gap.\n",
    "    \"\"\"\n",
    "    X = np.linspace(-2 * np.pi, 2 * np.pi, n_samples)\n",
    "    y = np.sin(X) + np.random.normal(0, noise_std, size=X.shape)\n",
    "\n",
    "    if gap_type == 'large':\n",
    "        # Large gap in the center\n",
    "        gap_mask = (X < -np.pi) | (X > np.pi)\n",
    "    elif gap_type == 'small':\n",
    "        # Small gap in the center\n",
    "        gap_mask = (X < -0.5 * np.pi) | (X > 0.5 * np.pi)\n",
    "    else:\n",
    "        raise ValueError(\"gap_type must be 'large' or 'small'\")\n",
    "\n",
    "    X_train = X[gap_mask]\n",
    "    y_train = y[gap_mask]\n",
    "\n",
    "    X_test = X\n",
    "    y_test = np.sin(X_test)\n",
    "\n",
    "    return X_train.reshape(-1, 1), y_train, X_test.reshape(-1, 1), y_test\n",
    "\n",
    "print(\"Generating datasets...\")\n",
    "X_train1, y_train1, X_test1, y_test1 = generate_sine_data(gap_type='large')\n",
    "X_train2, y_train2, X_test2, y_test2 = generate_sine_data(gap_type='small')\n",
    "print(\"Datasets generated.\\n\")\n",
    "\n",
    "def plot_datasets():\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    # Dataset 1: Large Gap\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_train1, y_train1, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test1, np.sin(X_test1), color='green', linewidth=2, label='True Function')\n",
    "    plt.title('Dataset 1: Large Gap', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "    # Dataset 2: Small Gap\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_train2, y_train2, color='red', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test2, np.sin(X_test2), color='green', linewidth=2, label='True Function')\n",
    "    plt.title('Dataset 2: Small Gap', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('datasets.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Plot 'datasets.png' saved.\\n\")\n",
    "\n",
    "plot_datasets()\n",
    "# Method 1: Exact GP and KRR\n",
    "def method1_gp_krr(X_train, y_train, X_test, y_test, noise=0.1, kernel_length=1.0, alpha=0.01):\n",
    "    times = {}\n",
    "\n",
    "    # Gaussian Process Regression\n",
    "    kernel = RBF(length_scale=kernel_length) + WhiteKernel(noise_level=noise**2)\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0, normalize_y=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gp.fit(X_train, y_train)\n",
    "    times['GP_fit'] = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    gp_mean, gp_std = gp.predict(X_test, return_std=True)\n",
    "    times['GP_predict'] = time.time() - start_time\n",
    "\n",
    "    # Kernel Ridge Regression\n",
    "    krr = KernelRidge(kernel='rbf', gamma=1.0 / (2 * kernel_length**2), alpha=alpha)\n",
    "\n",
    "    start_time = time.time()\n",
    "    krr.fit(X_train, y_train)\n",
    "    times['KRR_fit'] = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    krr_pred = krr.predict(X_test)\n",
    "    times['KRR_predict'] = time.time() - start_time\n",
    "\n",
    "    return gp_mean, gp_std, krr_pred, times\n",
    "\n",
    "print(\"Performing Method 1: Exact GP and KRR...\")\n",
    "gp_mean1, gp_std1, krr_pred1, times1 = method1_gp_krr(X_train1, y_train1, X_test1, y_test1)\n",
    "gp_mean2, gp_std2, krr_pred2, times2 = method1_gp_krr(X_train2, y_train2, X_test2, y_test2)\n",
    "print(\"Method 1 completed.\\n\")\n",
    "\n",
    "def plot_method1():\n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Dataset 1\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(X_train1, y_train1, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test1, np.sin(X_test1), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test1, gp_mean1, color='red', linewidth=1.5, label='GP Mean')\n",
    "    plt.fill_between(X_test1.ravel(),\n",
    "                     gp_mean1 - 2 * gp_std1,\n",
    "                     gp_mean1 + 2 * gp_std1,\n",
    "                     color='red', alpha=0.2, label='GP 95% CI')\n",
    "    plt.plot(X_test1, krr_pred1, color='purple', linewidth=1.5, label='KRR Prediction')\n",
    "    plt.title('Method 1: Exact GP and KRR on Dataset 1 (Large Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Dataset 2\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(X_train2, y_train2, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test2, np.sin(X_test2), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test2, gp_mean2, color='red', linewidth=1.5, label='GP Mean')\n",
    "    plt.fill_between(X_test2.ravel(),\n",
    "                     gp_mean2 - 2 * gp_std2,\n",
    "                     gp_mean2 + 2 * gp_std2,\n",
    "                     color='red', alpha=0.2, label='GP 95% CI')\n",
    "    plt.plot(X_test2, krr_pred2, color='purple', linewidth=1.5, label='KRR Prediction')\n",
    "    plt.title('Method 1: Exact GP and KRR on Dataset 2 (Small Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('method1_gp_krr.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Plot 'method1_gp_krr.png' saved.\\n\")\n",
    "\n",
    "plot_method1()\n",
    "\n",
    "# Method 2: Random Fourier Features (RFF)\n",
    "def generate_rff_features(X, m, sigma=1.0, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    d = X.shape[1]\n",
    "    omega = rng.normal(loc=0, scale=1.0 / sigma, size=(d, m))\n",
    "    b = rng.uniform(0, 2 * np.pi, size=m)\n",
    "    Z_cos = np.sqrt(2.0 / m) * np.cos(X @ omega + b)\n",
    "    Z_sin = np.sqrt(2.0 / m) * np.sin(X @ omega + b)\n",
    "    Z = np.hstack([Z_cos, Z_sin])\n",
    "    return Z\n",
    "\n",
    "def method2_rff(X_train, y_train, X_test, y_test, m=500, sigma=1.0, alpha=1e-3, random_state=42):\n",
    "    times = {}\n",
    "\n",
    "    # Generate RFF for training and test data\n",
    "    start_time = time.time()\n",
    "    Z_train = generate_rff_features(X_train, m, sigma, random_state)\n",
    "    Z_test = generate_rff_features(X_test, m, sigma, random_state)\n",
    "    times['RFF_feature_generation'] = time.time() - start_time\n",
    "\n",
    "    # Ridge Regression in feature space\n",
    "    start_time = time.time()\n",
    "    ridge = Ridge(alpha=alpha, fit_intercept=False)\n",
    "    ridge.fit(Z_train, y_train)\n",
    "    times['Ridge_fit'] = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = ridge.predict(Z_test)\n",
    "    times['Ridge_predict'] = time.time() - start_time\n",
    "\n",
    "    # Approximate Predictive Standard Deviation (simplified)\n",
    "    y_std = np.sqrt(alpha) * np.ones_like(y_pred)\n",
    "\n",
    "    return y_pred, y_std, times\n",
    "\n",
    "print(\"Performing Method 2: Random Fourier Features (RFF)...\")\n",
    "rff_pred1, rff_std1, times_rff1 = method2_rff(X_train1, y_train1, X_test1, y_test1)\n",
    "rff_pred2, rff_std2, times_rff2 = method2_rff(X_train2, y_train2, X_test2, y_test2)\n",
    "print(\"Method 2 completed.\\n\")\n",
    "\n",
    "def plot_method2():\n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Dataset 1\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(X_train1, y_train1, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test1, np.sin(X_test1), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test1, rff_pred1, color='orange', linewidth=1.5, label='RFF Prediction')\n",
    "    plt.fill_between(X_test1.ravel(),\n",
    "                     rff_pred1 - 2 * rff_std1,\n",
    "                     rff_pred1 + 2 * rff_std1,\n",
    "                     color='orange', alpha=0.2, label='RFF Approx. 95% CI')\n",
    "    plt.title('Method 2: RFF on Dataset 1 (Large Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Dataset 2\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(X_train2, y_train2, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test2, np.sin(X_test2), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test2, rff_pred2, color='orange', linewidth=1.5, label='RFF Prediction')\n",
    "    plt.fill_between(X_test2.ravel(),\n",
    "                     rff_pred2 - 2 * rff_std2,\n",
    "                     rff_pred2 + 2 * rff_std2,\n",
    "                     color='orange', alpha=0.2, label='RFF Approx. 95% CI')\n",
    "    plt.title('Method 2: RFF on Dataset 2 (Small Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('method2_rff.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Plot 'method2_rff.png' saved.\\n\")\n",
    "\n",
    "plot_method2()\n",
    "\n",
    "# Method 3: Performer's Random Feature Approach\n",
    "def generate_orthogonal_rff_features(X, m, sigma=1.0, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    d = X.shape[1]\n",
    "    if m % 2 != 0:\n",
    "        m += 1\n",
    "    omega = rng.normal(loc=0, scale=1.0 / sigma, size=(d, m))\n",
    "    # Orthogonalize using QR decomposition\n",
    "    omega, _ = qr(omega, mode='economic')\n",
    "    b = rng.uniform(0, 2 * np.pi, size=m)\n",
    "    Z_cos = np.sqrt(2.0 / m) * np.cos(X @ omega + b)\n",
    "    Z_sin = np.sqrt(2.0 / m) * np.sin(X @ omega + b)\n",
    "    Z = np.hstack([Z_cos, Z_sin])\n",
    "    return Z\n",
    "\n",
    "def method3_performer(X_train, y_train, X_test, y_test, m=500, sigma=1.0, alpha=1e-3, random_state=42):\n",
    "    times = {}\n",
    "\n",
    "    # Generate Orthogonal RFF for training and test data\n",
    "    start_time = time.time()\n",
    "    Z_train = generate_orthogonal_rff_features(X_train, m, sigma, random_state)\n",
    "    Z_test = generate_orthogonal_rff_features(X_test, m, sigma, random_state)\n",
    "    times['Performer_feature_generation'] = time.time() - start_time\n",
    "\n",
    "    # Ridge Regression in feature space\n",
    "    start_time = time.time()\n",
    "    ridge = Ridge(alpha=alpha, fit_intercept=False)\n",
    "    ridge.fit(Z_train, y_train)\n",
    "    times['Ridge_fit'] = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = ridge.predict(Z_test)\n",
    "    times['Ridge_predict'] = time.time() - start_time\n",
    "\n",
    "    # Approximate Predictive Standard Deviation (simplified)\n",
    "    y_std = np.sqrt(alpha) * np.ones_like(y_pred)\n",
    "\n",
    "    return y_pred, y_std, times\n",
    "\n",
    "print(\"Performing Method 3: Performer's Random Feature Approach...\")\n",
    "performer_pred1, performer_std1, times_perf1 = method3_performer(X_train1, y_train1, X_test1, y_test1)\n",
    "performer_pred2, performer_std2, times_perf2 = method3_performer(X_train2, y_train2, X_test2, y_test2)\n",
    "print(\"Method 3 completed.\\n\")\n",
    "\n",
    "def plot_method3():\n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Dataset 1\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(X_train1, y_train1, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test1, np.sin(X_test1), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test1, performer_pred1, color='magenta', linewidth=1.5, label='Performer Prediction')\n",
    "    plt.fill_between(X_test1.ravel(),\n",
    "                     performer_pred1 - 2 * performer_std1,\n",
    "                     performer_pred1 + 2 * performer_std1,\n",
    "                     color='magenta', alpha=0.2, label='Performer Approx. 95% CI')\n",
    "    plt.title('Method 3: Performer\\'s Orthogonal RFF on Dataset 1 (Large Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Dataset 2\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(X_train2, y_train2, color='blue', alpha=0.3, s=10, label='Training Data')\n",
    "    plt.plot(X_test2, np.sin(X_test2), color='green', linewidth=2, label='True Function')\n",
    "    plt.plot(X_test2, performer_pred2, color='magenta', linewidth=1.5, label='Performer Prediction')\n",
    "    plt.fill_between(X_test2.ravel(),\n",
    "                     performer_pred2 - 2 * performer_std2,\n",
    "                     performer_pred2 + 2 * performer_std2,\n",
    "                     color='magenta', alpha=0.2, label='Performer Approx. 95% CI')\n",
    "    plt.title('Method 3: Performer\\'s Orthogonal RFF on Dataset 2 (Small Gap)', fontsize=14)\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('method3_performer.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Plot 'method3_performer.png' saved.\\n\")\n",
    "\n",
    "plot_method3()\n",
    "\n",
    "# ----------------------------\n",
    "# Compute Condition Numbers\n",
    "# ----------------------------\n",
    "\n",
    "def compute_condition_numbers(\n",
    "    X_train1, X_train2,\n",
    "    y_train1, y_train2,\n",
    "    noise=0.1, kernel_length=1.0,\n",
    "    alpha_krr=0.01,\n",
    "    alpha_rff=1e-3,\n",
    "    m=500,\n",
    "    sigma=1.0,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the condition numbers for:\n",
    "    - Exact GP: condition number of (K + noise^2 I)\n",
    "    - Kernel Ridge: condition number of (K + alpha_krr I)\n",
    "    - RFF: condition number of (Z^T Z + alpha_rff I)\n",
    "    - Performer: condition number of (Z^T Z + alpha_rff I)\n",
    "    for both datasets.\n",
    "    \"\"\"\n",
    "    cond_numbers = {\n",
    "        'Exact GP': [],\n",
    "        'Kernel Ridge': [],\n",
    "        'RFF': [],\n",
    "        'Performer': []\n",
    "    }\n",
    "\n",
    "    # --- For dataset 1\n",
    "    n1 = len(X_train1)\n",
    "    K_gp_1 = rbf_kernel(X_train1, X_train1, gamma=1.0/(2*kernel_length**2))\n",
    "    K_gp_1 += (noise**2) * np.eye(n1)\n",
    "    cond_gp_1 = np.linalg.cond(K_gp_1)\n",
    "\n",
    "    K_krr_1 = rbf_kernel(X_train1, X_train1, gamma=1.0/(2*kernel_length**2))\n",
    "    K_krr_1 += alpha_krr * np.eye(n1)\n",
    "    cond_krr_1 = np.linalg.cond(K_krr_1)\n",
    "\n",
    "    Z_rff_1 = generate_rff_features(X_train1, m, sigma, random_state)\n",
    "    A_rff_1 = Z_rff_1.T @ Z_rff_1 + alpha_rff * np.eye(Z_rff_1.shape[1])\n",
    "    cond_rff_1 = np.linalg.cond(A_rff_1)\n",
    "\n",
    "    Z_perf_1 = generate_orthogonal_rff_features(X_train1, m, sigma, random_state)\n",
    "    A_perf_1 = Z_perf_1.T @ Z_perf_1 + alpha_rff * np.eye(Z_perf_1.shape[1])\n",
    "    cond_perf_1 = np.linalg.cond(A_perf_1)\n",
    "\n",
    "    cond_numbers['Exact GP'].append(cond_gp_1)\n",
    "    cond_numbers['Kernel Ridge'].append(cond_krr_1)\n",
    "    cond_numbers['RFF'].append(cond_rff_1)\n",
    "    cond_numbers['Performer'].append(cond_perf_1)\n",
    "\n",
    "    # --- For dataset 2\n",
    "    n2 = len(X_train2)\n",
    "    K_gp_2 = rbf_kernel(X_train2, X_train2, gamma=1.0/(2*kernel_length**2))\n",
    "    K_gp_2 += (noise**2) * np.eye(n2)\n",
    "    cond_gp_2 = np.linalg.cond(K_gp_2)\n",
    "\n",
    "    K_krr_2 = rbf_kernel(X_train2, X_train2, gamma=1.0/(2*kernel_length**2))\n",
    "    K_krr_2 += alpha_krr * np.eye(n2)\n",
    "    cond_krr_2 = np.linalg.cond(K_krr_2)\n",
    "\n",
    "    Z_rff_2 = generate_rff_features(X_train2, m, sigma, random_state)\n",
    "    A_rff_2 = Z_rff_2.T @ Z_rff_2 + alpha_rff * np.eye(Z_rff_2.shape[1])\n",
    "    cond_rff_2 = np.linalg.cond(A_rff_2)\n",
    "\n",
    "    Z_perf_2 = generate_orthogonal_rff_features(X_train2, m, sigma, random_state)\n",
    "    A_perf_2 = Z_perf_2.T @ Z_perf_2 + alpha_rff * np.eye(Z_perf_2.shape[1])\n",
    "    cond_perf_2 = np.linalg.cond(A_perf_2)\n",
    "\n",
    "    cond_numbers['Exact GP'].append(cond_gp_2)\n",
    "    cond_numbers['Kernel Ridge'].append(cond_krr_2)\n",
    "    cond_numbers['RFF'].append(cond_rff_2)\n",
    "    cond_numbers['Performer'].append(cond_perf_2)\n",
    "\n",
    "    return cond_numbers\n",
    "\n",
    "print(\"Computing condition numbers for all methods...\")\n",
    "cond_nums = compute_condition_numbers(\n",
    "    X_train1, X_train2,\n",
    "    y_train1, y_train2,\n",
    "    noise=0.1,\n",
    "    kernel_length=1.0,\n",
    "    alpha_krr=0.01,\n",
    "    alpha_rff=1e-3,\n",
    "    m=500,\n",
    "    sigma=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_cond = pd.DataFrame(cond_nums, index=[\"Dataset 1 (Large Gap)\", \"Dataset 2 (Small Gap)\"])\n",
    "print(\"Condition Numbers:\")\n",
    "print(df_cond, \"\\n\")\n",
    "def summarize_methods():\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    methods = ['Exact GP', 'Kernel Ridge', 'RFF', 'Performer']\n",
    "    datasets = ['Dataset 1 (Large Gap)', 'Dataset 2 (Small Gap)']\n",
    "    mse = {\n",
    "        'Exact GP': [mean_squared_error(y_test1, gp_mean1),\n",
    "                     mean_squared_error(y_test2, gp_mean2)],\n",
    "        'Kernel Ridge': [mean_squared_error(y_test1, krr_pred1),\n",
    "                         mean_squared_error(y_test2, krr_pred2)],\n",
    "        'RFF': [mean_squared_error(y_test1, rff_pred1),\n",
    "                mean_squared_error(y_test2, rff_pred2)],\n",
    "        'Performer': [mean_squared_error(y_test1, performer_pred1),\n",
    "                      mean_squared_error(y_test2, performer_pred2)]\n",
    "    }\n",
    "\n",
    "    cpu_times = {\n",
    "        'Exact GP Fit (s)': [times1['GP_fit'], times2['GP_fit']],\n",
    "        'Exact GP Predict (s)': [times1['GP_predict'], times2['GP_predict']],\n",
    "        'KRR Fit (s)': [times1['KRR_fit'], times2['KRR_fit']],\n",
    "        'KRR Predict (s)': [times1['KRR_predict'], times2['KRR_predict']],\n",
    "        'RFF Feature Gen (s)': [times_rff1['RFF_feature_generation'], times_rff2['RFF_feature_generation']],\n",
    "        'RFF Ridge Fit (s)': [times_rff1['Ridge_fit'], times_rff2['Ridge_fit']],\n",
    "        'RFF Predict (s)': [times_rff1['Ridge_predict'], times_rff2['Ridge_predict']],\n",
    "        'Performer Feature Gen (s)': [times_perf1['Performer_feature_generation'], times_perf2['Performer_feature_generation']],\n",
    "        'Performer Ridge Fit (s)': [times_perf1['Ridge_fit'], times_perf2['Ridge_fit']],\n",
    "        'Performer Predict (s)': [times_perf1['Ridge_predict'], times_perf2['Ridge_predict']],\n",
    "    }\n",
    "\n",
    "    df_mse = pd.DataFrame(mse, index=datasets).round(6)\n",
    "    df_cpu = pd.DataFrame(cpu_times, index=datasets).round(4)\n",
    "    df_combined = pd.concat([df_mse, df_cpu], axis=1)\n",
    "\n",
    "    df_cond_renamed = df_cond.rename(columns={\n",
    "         'Exact GP': 'Exact GP Cond',\n",
    "         'Kernel Ridge': 'Kernel Ridge Cond',\n",
    "         'RFF': 'RFF Cond',\n",
    "         'Performer': 'Performer Cond'\n",
    "    })\n",
    "    df_final = pd.concat([df_combined, df_cond_renamed], axis=1)\n",
    "    df_final.to_csv('comparison_table.csv')\n",
    "\n",
    "    print(\"Comparison of Methods (Mean Squared Error, CPU Times, and Condition Numbers):\") # For COmmand line debugging\n",
    "    print(df_final)\n",
    "    print(\"\\nSummary table saved as 'comparison_table.csv'.\\n\")\n",
    "\n",
    "summarize_methods()\n",
    "\n",
    "print(\"All plots, tables, and condition number calculations have been sucesfully generated and saved!!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
